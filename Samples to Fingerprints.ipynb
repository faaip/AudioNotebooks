{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook converts `samples.npy` to `fingerprints.npy`. After processing, check the max and mean images to make sure that you are not over- or under-cropping the data. Set `crop_rows` or `crop_cols` to `None` to see all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data/drums/'\n",
    "n_fft = 1024\n",
    "hop_length = n_fft//4\n",
    "use_logamp = False # boost the brightness of quiet sounds\n",
    "reduce_rows = 10 # how many frequency bands to average into one\n",
    "reduce_cols = 1 # how many time steps to average into one\n",
    "crop_rows = 32 # limit how many frequency bands to use\n",
    "crop_cols = 32 # limit how many time steps to use\n",
    "limit = None # set this to 100 to only process 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.measure import block_reduce\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time samples = np.load(join(data_root, 'samples.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "window = np.hanning(n_fft)\n",
    "def job(y):\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, window=window)\n",
    "    amp = np.abs(S)\n",
    "    if reduce_rows > 1 or reduce_cols > 1:\n",
    "        amp = block_reduce(amp, (reduce_rows, reduce_cols), func=np.mean)\n",
    "    if amp.shape[1] < crop_cols:\n",
    "        amp = np.pad(amp, ((0, 0), (0, crop_cols-amp.shape[1])), 'constant')\n",
    "    amp = amp[:crop_rows, :crop_cols]\n",
    "    if use_logamp:\n",
    "        amp = librosa.logamplitude(amp**2)\n",
    "    amp -= amp.min()\n",
    "    if amp.max() > 0:\n",
    "        amp /= amp.max()\n",
    "    amp = np.flipud(amp) # for visualization, put low frequencies on bottom\n",
    "    return amp\n",
    "pool = Pool()\n",
    "%time fingerprints = pool.map(job, samples[:limit])\n",
    "fingerprints = np.asarray(fingerprints).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(join(data_root, 'fingerprints.npy'), fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('data shape:', np.shape(fingerprints))\n",
    "\n",
    "mean = np.mean(fingerprints, axis=0)\n",
    "mean -= mean.min()\n",
    "mean /= mean.max()\n",
    "\n",
    "print ('mean:')\n",
    "show_array(255 * mean)\n",
    "print ('max:')\n",
    "show_array(255 * np.max(fingerprints, axis=0))\n",
    "\n",
    "print ('random selection:')\n",
    "indices = range(len(fingerprints))\n",
    "np.random.shuffle(list(range(len(indices))))\n",
    "show_array(255 * make_mosaic(np.array(fingerprints)[indices], n=16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AudioNotebooks",
   "language": "python",
   "name": "audionotebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
